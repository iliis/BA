\chapter{Optimizations and Other Improvements}
\label{sec:optimizations}

The algorithm described in the chapter~\ref{sec:method} works well but suffers from
slow performance and is not nearly realtime capable on an embedded device.
Therefore, some optimization strategies are applied:

\section{Image Pyramids}
\label{sec:pyramids}

A common optimization technique is the use of multiple resolutions: Images are
repeatedly filtered and downscaled by a factor of two (effectively quartering
the number of pixels) by averaging over a $2 \times 2$ pixel block to generate
a stack of increasingly smaller images (a 'pyramid').

The minimization is run on the smallest set of images and the resulting value
is used as an initial value for the next bigger set of images.
This greatly reduces the number of iterations required and enhances the
convergence radius.

The image pyramid can also be used to trade a bit of accuracy for even more
performance gain by simply aborting early and not using the full resolution at
all. Throwing out the one or two lowermost levels usually incurs negligible
loss of accuracy (see also section~\ref{sec:results_qualitative}).


\section{Pixel Selection by Image Gradient}
\label{sec:gradient_filtering}

We can further optimize away pixels which do not strongly influence the
minimization such as points in homogenous image regions where $\nabla
\mathbf{I} \approx 0$ and therefore $\mat{J_I} \approx 0$.

This is already provided to some extent by the semi-global matching alorithm,
as pixels without strong gradients are usually hard to match and therefore often
do not provide a disparity value.

\section{Handling Outliers}

By robustly weighting the photometric error terms outliers can be dampened to
reduce the influence of occlusions, moving scenery or other noise, such as
errors from the semi-global matcher. This improves quality and stability with
negligible performance penalty.

Another idea (which was not fully investigated) to handle occlusions is to use a
Z-buffer to eliminate points which are behind others when warped. However, as
photometric odometry works very incrementally, large occlusions are scarce.

\section{Further Possible Optmiziations}

A few things which have not been investigated in this work but which provide
good avenues for further optimizations:

\subsection{Integration of an IMU}

Modern visual odometry and SLAM systems such as \cite{leutenegger2013keyframe}
incorporate data from an inertial measurement unit using various complicated
filtering schemes to increase accuracy.
In contrast, using integrated acceleration values for pohotometric odometry
would be easy by simply providing a good initial guess for the minimization
process and could greatly speed up perfomance by reducing the number of
required optimization iterations.

\subsection{Keyframes}

Instead of always matching the previous frame, keyframes can be used instead
which are only updated when the relative motion grows above some threshold.
This way, drift can be reduced and even completely eliminated when being more
or less stationary.

\subsection{Offload More Work to FPGA or Multi-Core}

Large parts of the photometric odometry algorithm are highly parallelizable and
would profit from an implementation running on the FPGA. As this is one of the
main point of this work, it is further discussed in section~\ref{sec:timing}.



